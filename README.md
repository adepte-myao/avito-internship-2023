# Сервис динамического сегментирования пользователей

## Возникшие вопросы
### 1. Как работать с файлами?
В доп. задании 1 необходимо сформировать csv-файл и вернуть ссылку для его получения. Я вижу следующие решения 
(со стороны сервиса):
1. Возвращать ссылку на метод того же сервиса, формирующий файл и сразу возвращающий его. Самое простое решение; 
к тому же, не требующее дополнительного взаимодействия по сети. Если не хватит времени на остальные решения, то – оптимальный вариант.
2. Создавать файл и отправлять его на самописный файловый сервер. Необходимо разработать файловый сервер, не подходит.
3. Использовать self-hosted файловый сервер, [например](https://github.com/drakkan/sftpgo). Нужно изучать документацию 
по API и настраивать.
4. Использовать cloud-решение, например, dropbox. Нужно изучать документацию по API. Если по времени успею – оптимальный вариант.
### 2. Нужно ли хранить список пользователей?
В доп. задании 3 необходимо реализовать функционал, добавляющий n% от ВСЕХ пользователей в заданный сегмент. 
Значит, нужно откуда-то получить идентификаторы всех пользователей. Вижу следующие варианты:
1. По необходимости делать запрос вроде /users/get-all-ids с целью получения идентификаторов всех пользователей. 
Если база данных сервиса пользователей содержит несколько миллионов записей, запрос займет слишком много времени 
(несколько секунд времени сервиса пользователей). Неоптимально, поскольку, помимо большой нагрузки на сервис 
пользователей, метод не предполагает никакого сохранения полученных данных (кэш в худшем случае будет обновляться каждую минуту).
2. Держать на сервисе реплику таблицы пользователей (важны только идентификаторы и состояние пользовательского аккаунта). 
Поддерживать консистентность можно так:
   1. С помощью внутренних механизмов баз данных. Сложно (требует вмешательства DBA) и, возможно, получится поддерживать 
   только реплику ВСЕЙ таблицы пользователей, хотя нам нужны только 2 поля.
   2. Сервис пользователей при обновлении состояния вызывает метод у сервиса сегментирования. Негибко и противоречит 
   направлению зависимости между сервисами.
   3. Сервис пользователей при обновлении состояния отправляет событие с идентификатором пользователя в брокер сообщений. 
   Сервис сегментирования при получении события делает запрос к сервису пользователей с целью получения состояния. 
   Отправлять обновленное состояние сразу в брокер не стоит, поскольку, во-первых, состояние к моменту обработки на 
   сервисе сегментирования может измениться, а во-вторых, потому что возможны ситуации, при которых сервис 
   сегментирования получит события не в том порядке, в котором они были отправлены, что приведет к ошибке.
  
Приоритет: Must have
### 3. Нужно ли дублировать асинхронное взаимодействие HTTP-методами?
Необходимость в наличии HTTP-методов для добавления / удаления / изменения состояния пользователей может возникнуть в 
ситуации, когда развертывается новый сервис сегментирования, его базу необходимо заполнить новыми пользователями, и 
сделать это с помощью публикации событйи в брокер сообщений по какой-то причине невозможно. Для этой цели (а заодно – 
для облегчения заполнения базы данных без обеспечения прямого доступа к ней), я реализую набор соответствующих dev-only методов. 

Приоритет: Must have
### 4. Нужны ли механизмы аутентификации / авторизации для взаимодействия с сервисом?
Поскольку прямого взаимодействия с фронтендом может и не быть, эти механизмы необязательны; однако, для повышения 
безопасности, их стоит добавить.

Приоритет: Nice to have
### 5. Какой тип у идентификаторов?
У пользователей я вижу два варианта: числовой (автоматически генерируемый в базе данных) и GUID. Предпочту GUID, 
поскольку он с большой вероятностью позволяет избежать коллизий при использовании нескольких баз данных одновременно, 
например, в случае ее шардирования. У сегментов я выберу вариант с ключом, равным названию сегмента. Остальные варианты 
предполагают существование нескольких сегментов с одинаковым названием, что может привести к противоречиям.

## Итоги по вопросам
1. Если получится, реализую интеграцию с dropbox для работы с отчетами. В противном случае сделаю выдачу отчета по 
ссылке, при нажатии на которую и будет генерироваться отчет.
2. Список пользователей будет храниться локально. Для его обновления разработаю консьюмера для Kafka, обработка которого 
будет заключаться в получении актуального состояния пользователя со стороны сервиса пользователей и его обновления локально.
3. Для ручного управления репликой таблицы пользователей разработаю набор методов.
4. Если получится, добавлю механизмы аутентификации и авторизации по ролям (предполагаемые роли: админ, аналитик)
5. Идентификатор пользователей – GUID, сегментов – их названия.

## Потенциальные будущие требования и способы их реализации
### 1. Один сервис не справится с нагрузкой, надо как-то масштабировать
В случае, если базу данных масштабировать не нужно / база данных может быть масштабирована с сохранением stateless-статуса 
инстанса сервиса, сервис может быть без проблем масштабирован до любого количества инстансов. Это возможно благодаря тому, 
что сервис использует базу данных для хранения состояния. Единственный видимый мне сценарий, при котором сервис не может 
быть масштабирован в исходном виде – база данных шардирована и не приспособлена к перенаправлению запроса на нужный инстанс. 
То есть, если запрос отправить на сервис, подключенный не к тому шарду, запрос будет выполнен неверно. Из такой ситуации 
вижу следующие выходы:
1. Перейти к базе данных, способной выбрать верный шард
2. Реализовать логику выбора верного шарда на стороне сервиса
3. Реализовать перед сервисами контроллер, перенаправляющий запрос на нужный сервис.
### 2. Хочется получать список всех пользователей из некоторого сегмента
Чтобы это сделать, можно реализовать соответсвующий метод. В случае большой выборки (если сегменту принадлежит >10% от 
всех пользователей, а самих пользователей – миллионы) возможны зависания. Обратная совместимость сохранится.
### 3. При автоматическом сегментировании хочется указать сегменты в качестве фильтров пользователей для сегментирования (семантика include / exclude)
Для реализации в запрос можно добавить опциональные поля exclude и include, обратная совместимость сохранится.
### 4. При автоматическом сегментировании хочется указать TTL
Для реализации в запрос можно добавить опциональное поле time_to_live, обратная совместимость сохранится.
